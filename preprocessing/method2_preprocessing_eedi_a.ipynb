{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate answer question data remove\n",
    "df_eedi = pd.read_csv('./data/eedi_a/train_task_1_2.csv')\n",
    "df_eedi\n",
    "\n",
    "filtered_df = df_eedi.groupby('QuestionId').filter(lambda x: x[(x.IsCorrect == 1)]['CorrectAnswer'].nunique() <= 1 and x[(x.IsCorrect == 0)]['CorrectAnswer'].nunique() <= 1)\n",
    "null_list = df_eedi[~df_eedi.index.isin(filtered_df.index)]['QuestionId'].unique().tolist()\n",
    "# null_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(null_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline id_dic_construction\n",
    "def id_dic_construction(x):\n",
    "    corresponding_dic = {}\n",
    "    for dic_index in range(len(x)):\n",
    "        corresponding_dic[x[dic_index]] = dic_index\n",
    "    return corresponding_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline id_dic\n",
    "\n",
    "# Extract question_info \n",
    "question_info = pd.read_csv('./data/eedi_a/question_metadata_task_1_2.csv')\n",
    "print(question_info.columns)\n",
    "question_info = question_info.drop_duplicates()\n",
    "for q in tqdm(null_list):\n",
    "    question_info = question_info.drop(question_info[question_info['QuestionId'] == q].index)\n",
    "question_info = question_info.values\n",
    "\n",
    "# Extract question_id\n",
    "question_id = np.unique(question_info[:, 0])\n",
    "question_dic = id_dic_construction(question_id)\n",
    "\n",
    "# Extract skill_id\n",
    "for i, kc in enumerate(tqdm(question_info)):\n",
    "    question_info[i, 1] = list(map(int, kc[1][1:-1].split(',')))\n",
    "skill = []\n",
    "for i in tqdm(range(len(question_info))):\n",
    "    skill += question_info[i, 1]\n",
    "skill = np.unique(np.array(skill).astype('int64'))\n",
    "skill_dic = id_dic_construction(skill)\n",
    "\n",
    "# question, skill renaming with dictionary\n",
    "for i in tqdm(range(len(question_info))):\n",
    "    question_info[i, 0] = question_dic[question_info[i, 0]]\n",
    "    for n in range(len(question_info[i, 1])):\n",
    "        question_info[i, 1][n] = skill_dic[question_info[i, 1][n]]\n",
    "question_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make baseline q_matrix\n",
    "tmp_question_skill_cell = []\n",
    "for i in tqdm(range(len(question_info))):\n",
    "    q_id = question_info[i, 0]\n",
    "    skill = question_info[i, 1]\n",
    "    for kc in np.array(skill).astype('int64'):\n",
    "        tmp_question_skill_cell.append([q_id, kc])\n",
    "tmp_question_skill_cell = np.array(tmp_question_skill_cell)\n",
    "exercise_num = len(question_dic)\n",
    "skill_num = len(skill_dic)\n",
    "tmp_exercise_id = tmp_question_skill_cell[:, 0]\n",
    "tmp_skill_id = tmp_question_skill_cell[:, 1]\n",
    "baseline_q_matrix = np.zeros([exercise_num, skill_num])\n",
    "for i in tqdm(range(len(tmp_question_skill_cell))):\n",
    "    baseline_q_matrix[int(tmp_exercise_id[i]), int(tmp_skill_id[i])] = 1\n",
    "baseline_q_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/eedi_a/q_matrix_eedi_a.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline_q_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract student id\n",
    "# student_info = pd.read_csv('./data/eedi_a/student_metadata_task_1_2.csv')\n",
    "# student_info = student_info.drop_duplicates()\n",
    "# student_info = student_info.values\n",
    "\n",
    "# student_id = np.unique(student_info[:, 0])\n",
    "# student_dic = id_dic_construction(student_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_info = pd.read_csv('./data/eedi_a/answer_metadata_task_1_2.csv')\n",
    "answer_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eedi = pd.read_csv('./data/eedi_a/train_task_1_2.csv')\n",
    "df_eedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate answer question data remove\n",
    "filtered_df_eedi = df_eedi.groupby('QuestionId').filter(lambda x: x[(x.IsCorrect == 1)]['CorrectAnswer'].nunique() <= 1 and x[(x.IsCorrect == 0)]['CorrectAnswer'].nunique() <= 1)\n",
    "df_eedi = filtered_df_eedi\n",
    "df_eedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/eedi_a/eedi_a_noise_remove_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(df_eedi, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eedi = pd.read_pickle('./data/eedi_a/eedi_a_noise_remove_data.pkl')\n",
    "# df_eedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe question renaming\n",
    "df_eedi.iloc[:, 0] = df_eedi.iloc[:, 0].map(question_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df = pd.DataFrame([(question[0], question[1]) for question in question_info], columns=[\"QuestionId\", \"SubjectId\"])\n",
    "question_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge question df\n",
    "df_eedi = pd.merge(df_eedi, question_df, how='inner', on='QuestionId')\n",
    "df_eedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eedi = df_eedi[['UserId', 'QuestionId', 'AnswerValue', 'AnswerId', 'CorrectAnswer', 'SubjectId', 'IsCorrect']]\n",
    "df_eedi.columns = ['UserId', 'QuestionId', 'AnswerValue', 'AnswerId', 'CorrectAnswer', 'tag', 'IsCorrect']\n",
    "df_eedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eedi_values = df_eedi.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem solving rate of each student\n",
    "from collections import defaultdict\n",
    "\n",
    "problem_solving_rate = defaultdict(int)\n",
    "grouped = df_eedi.groupby(df_eedi.iloc[:, 0])\n",
    "for student, group in tqdm(grouped):\n",
    "    unique_questions = group.iloc[:, 1].unique()\n",
    "    problem_solving_rate[student] = len(unique_questions) / len(question_dic)\n",
    "dict(problem_solving_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of total correct answers for each student\n",
    "correct_rate = defaultdict(int)\n",
    "grouped = df_eedi.groupby(df_eedi.iloc[:, 0])\n",
    "for student, group in tqdm(grouped):\n",
    "    if len(group.iloc[:, 6]) == 0:\n",
    "        correct_rate[student] = 0\n",
    "    else:\n",
    "        correct_rate[student] = sum(group.iloc[:, 6])/len(group.iloc[:, 6])\n",
    "correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dicttionary with a list of students who solved each problem\n",
    "problem_student = defaultdict(int)\n",
    "grouped = df_eedi.groupby(df_eedi.iloc[:, 1])\n",
    "for question, group in tqdm(grouped):\n",
    "    unique_students = group.iloc[:, 0].unique()\n",
    "    problem_student[question] = unique_students\n",
    "problem_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pick leading group\n",
    "leading_group = {}\n",
    "problem_solving_rate_upper_bound = 0.4 # problem solving upper bound\n",
    "correct_rate_upper_bound = 0.4 # correct rate upper bound\n",
    "for key in tqdm(problem_student):\n",
    "    tmp = np.empty((0, 3), float)\n",
    "    for student in problem_student[key]:\n",
    "        tmp = np.append(tmp, np.array([[student, problem_solving_rate[student], correct_rate[student]]]), axis=0)\n",
    "    pro_solv_rate_sorted_idx = np.argsort(tmp[:, 1])[::-1]\n",
    "    tmp = tmp[pro_solv_rate_sorted_idx]\n",
    "    pro_solv_rate_up_bound = int(np.round(len(tmp[:, 1])*problem_solving_rate_upper_bound))\n",
    "    tmp = tmp[:pro_solv_rate_up_bound+1]\n",
    "    cor_rate_sorted_idx = np.argsort(tmp[:, 2])[::-1]\n",
    "    tmp = tmp[cor_rate_sorted_idx]\n",
    "    cor_rate_up_bound = int(np.round(len(tmp[:, 2])*correct_rate_upper_bound))\n",
    "    tmp_leading_group = tmp[:cor_rate_up_bound+1]\n",
    "    leading_group[key] = tmp_leading_group[:, 0].astype(int)\n",
    "# leading_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option weight extraction based on the option selection rate of the leading group\n",
    "\n",
    "opt_dic = {}\n",
    "for key, group in tqdm(df_eedi.groupby('QuestionId')):\n",
    "    tmp_opt_list = []\n",
    "    tmp_opt_dic = {}\n",
    "    for i in leading_group[key]:\n",
    "        filtered_df = group[group['UserId'] == i]\n",
    "        tmp_opt_list += list(filtered_df['AnswerValue'])\n",
    "        correct_answer = list(filtered_df['CorrectAnswer'])[0]\n",
    "    tmp_opt_dic[1] = tmp_opt_list.count(1) / len(tmp_opt_list) if len(tmp_opt_list) != 0 else 0\n",
    "    tmp_opt_dic[2] = tmp_opt_list.count(2) / len(tmp_opt_list) if len(tmp_opt_list) != 0 else 0\n",
    "    tmp_opt_dic[3] = tmp_opt_list.count(3) / len(tmp_opt_list) if len(tmp_opt_list) != 0 else 0\n",
    "    tmp_opt_dic[4] = tmp_opt_list.count(4) / len(tmp_opt_list) if len(tmp_opt_list) != 0 else 0\n",
    "    tmp_opt_dic[correct_answer] = 2.0\n",
    "    sorted_dic = dict(sorted(tmp_opt_dic.items(), key=lambda x: x[1]))\n",
    "    sorted_keys = list(sorted_dic.keys())\n",
    "    tmp_opt_dic[sorted_keys[0]] = 1\n",
    "    tmp_opt_dic[sorted_keys[1]] = 2\n",
    "    tmp_opt_dic[sorted_keys[2]] = 3\n",
    "    tmp_opt_dic[sorted_keys[3]] = 4\n",
    "    opt_dic[key] = tmp_opt_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eedi_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Option Weight\n",
    "option_list = []\n",
    "for i in tqdm(range(len(df_eedi_values))):\n",
    "    option_list.append(opt_dic[df_eedi_values[i, 1]][df_eedi_values[i, 2]])\n",
    "df_eedi['OptionWeight'] = option_list\n",
    "df_eedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract if it is wrong, but the option weight is 4 ==> nothing should come out, it is normal\n",
    "df_eedi[(df_eedi['IsCorrect']==0)&(df_eedi['OptionWeight']==4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pickle file\n",
    "# with open(f'./data/eedi/method2/base_eedi_a_option_{problem_solving_rate_upper_bound}_{correct_rate_upper_bound}.pkl', 'wb') as f:\n",
    "#     pickle.dump(df_eedi, f)\n",
    "with open(f'./data/eedi_a/method_2/eedi_a.pkl', 'wb') as f:\n",
    "    pickle.dump(df_eedi, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamp Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_answer_info = answer_info[['AnswerId', 'DateAnswered']]\n",
    "df_eedi = pd.merge(df_eedi, tmp_answer_info, how='inner', on='AnswerId')\n",
    "df_eedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "# datetime to timestamp \n",
    "eedi_time = list(df_eedi['DateAnswered'])\n",
    "for i, timestr in enumerate(tqdm(eedi_time)):    \n",
    "    eedi_time[i] = time.mktime(datetime.datetime.strptime(str(timestr[:-4]), \"%Y-%m-%d %H:%M:%S\").timetuple())\n",
    "eedi_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save timestamp\n",
    "\n",
    "df_eedi['DateAnswered'] = eedi_time\n",
    "df_eedi = df_eedi.sort_values(by=['DateAnswered'])\n",
    "df_eedi.reset_index(drop = True, inplace = True)\n",
    "df_eedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/eedi_a/method_2/eedi_a.pkl', 'wb') as f:\n",
    "    pickle.dump(df_eedi, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
